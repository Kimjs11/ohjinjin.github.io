---
title: "Review Paper-ImageNet Classification with Deep Convolutional Neural Networks"
categories: 
  - MachineLearning
last_modified_at: 2020-09-23T16:52:00+09:00
toc: true
published: false
---

Deep Convolutional Neural Netwworks로 이미지넷 분류

초록
ImageNet NSVRC-2010 대회의 1.2 million 고해상도 이미지를 1000개의 서로 다른 클래스로 분류하기 위해 크고 깊은 컨볼루셔널 뉴럴 네트워크를 학습시켰다. 테스트 데이터에서 우리는 top-1과 top-5 error rates에서 각각 37.5%와 17.0%로 앞선 SOTA보다 상당히 더 나은 결과를 얻었다. 60 million 파라미터와 650,000 뉴런을 가진 이 뉴럴네트워크는 5개의 컨볼루셔널 레이어와 max 풀링을 따르는 레이어, 마지막 1000-way 소프트맥스를 갖으며 총 세 개의 fc 레이어로 이루어졌다. 학습을 빠르게 하기 위해, 우리는 비포화 뉴런을 사용하였고, 컨볼루션 연산에 매우 효율적인 GPU 구현을 사용하였다. FC 레이어에서의 오버피팅을 줄이기 위해서 우리는 매우 효율적임이 입증된 dropout이라 불리는 최신 개발된 regularization method를 채용했다. 우리는 또한 ILSVRC-2012 컴피티션에서 이 모델의 다양성을 도입했다 그리고 2등과 26.2%의 차이나 나는 15.3%의 top-5 error rate을 달성했다.

객체 인식에 대한 현재 접근들은 머신러닝 메소드의 사용을 필수적으로 하고 있다. 그들의 성능을 높이기 위해서 우리는 대규모 데이터셋을 수집할 수 있으며, 파워풀한 모델을 만들고, 오버피팅을 막기 위해 더 나은 기법을 사용할 수 있다. 최근까지는 레이블된 이미지들의 데이터셋은 상대적으로 작았다. 단순한 인식을 하는 태스크는 이러한 사이즈의 데이터셋과 꽤 잘 풀릴 수 있다. 특히 그들이 만약 레이블을 유지하는 변형을 통해 증식된다면. 예를 들어 MNIST 숫자 인식에 대한 현재 최고 error rate은 0.3%보다 작아 인간 지능에 접근하고 있다. 그러나 현실적인 세팅의 객체들은 상당히 가변적이므로  그것들을 인식하도록 학습하기 위해서 훨씬 더 큰 트레이닝 셋을 사용할 필요가 있다. 실제로 작은 이미지 데이터셋의 단점은 넓게 인식되어 왔지만, 최근에서야 수백만개의 이미지로 레이블링 된 데이터셋을 수집하는 것이 가능해졌다. 새로운 큰 규모의 데이터셋은 fully segmented 이미지 수천 수백개로 구성된 LabelMe와 22,000 이상 카테고리를 가진 15 million 이상의 레이블링된 고해상도 이미지로 구성된 ImageNet을 포함한다.

수 million의 이미지로부터 수천개의 객체를 학습하기 위해서 우리는 큰 학습 수용량을 갖는 모델이 필요하다. 그러나 객체 인식 태스크의 큰 복잡도는 이 문제가 ImageNet 만큼이나 큰 데이터셋에 의해서도 구체화되지 않는다는 것을 의미하므로 우리의 모델은 또한 우리가 가지고 있지 않은 모든 데이터를 커버할 많은 사전지식을 가지고 있어야한다. 컨볼루셔널 뉴럴 네트워크는 이러한 모델 클래스와 같은 하나를 구성한다. 그들의 용량은 그들의 깊이와 너비를 다양화함으로써 제어가 가능하고 CNN은 또한 자연 이미지에 대한 가정(즉, 통계적 공간성과 픽셀의존성의 지역화)들을 강하고 정확하게 만든다. 따라서 표준 비슷한 레이어 규모의 feedforward NN과 비교하여 CNN은 이론적으로 그들의 최고의 성능이 아주 경미하게 나쁠 수 있다는 가능성이 있다는 반면, 훨씬 더 적은 커넥션과 파라미터를 가지므로 학습하기 쉬워진다.

CNN의 매력적인 품질에도 불구하고 그리고 그들의 지역적아키텍쳐의 상대적인 효율성에도 불구하고 CNN은 여전히 대규모의 고해상도 이미지에 적용하기에는 코스트가 꽤 크다. 다행히도 2D 컨볼루션의 고도로 최적화된 구현과 쌍을 이루는 현재 GPU는 흥미롭게도 큰 CNN의 훈련을 용이하게 할 만큼 충분히 강력하며, ImageNet과 같은 최근 데이터 셋에는 심각한 overfitting 없이 이러한 모델을 훈련하기에 충분한 레이블이 지정된 예제가 포함되어있다.

이 논문의 구체적인 기여는 다음과 같다: 우리는 ILSVRC-2010 and ILSVRC-2012에 사용된 ImageNet 섭셋을 위해 큰 CNN을 훈련시켰고 이 데이터셋에 대해 보고된 지금까지의 최고의 결과를 달성했다. 우리는 2D 컨볼루션의 고도로 최적화 된 GPU 구현과 컨볼 루션 신경망 훈련에 내재 된 다른 모든 작업을 작성하여 공개적으로 제공했다.

우리의 네트워크에는 성능을 향상시키고 훈련 시간을 줄이는 여러 가지 새롭고 특이한 기능이 포함되어 있다. 이는 섹션 3에 자세히 설명되어 있다. 우리 네트워크의 크기로 인해 120 만 개의 레이블이 지정된 훈련 예제에서도 과적 합이 심각한 문제가되었으므로 몇 가지를 사용했다. 과적 합을 방지하기위한 효과적인 기술은 섹션 4에 설명되어 있습니다. 최종 네트워크에는 5 개의 컨벌루션 레이어와 3 개의 완전 연결 레이어가 포함되어 있으며이 깊이가 중요해보인다.: 컨볼 루션 레이어 (모델 파라미터의 1%미만을 포함하는)를 제거하는 것이 성능을 저하시킨다는 것을 발견했다.

결국 네트워크의 규모는 주로 현재 GPU에서 사용할 수 있는 메모리 양과 우리가 기꺼이 허용할 훈련시간에 의해 제한되곤 한다. 우리의 네트워크는 2개의 GTX580 3GB GPU에서 학습하는데 5-6일이 소요된다. 우리의 모든 실험은 우리의 결과가 더 빠른 GPU와 더 큰 데이터셋을 사용할 수 있을 때까지 기다리는 것 만으로도 개선될 수 있음을 제안한다.

2. 데이터셋
ImageNet은 약 22,000 개 카테고리에 속하는 1,500 만 개 이상의 레이블이 지정된 고해상도 이미지로 구성된 데이터 세트이다. 이미지는 웹에서 수집하고 Amazon의 Mechanical Turk 크라우드 소싱 도구를 사용하여 라벨링 담당자가 라벨을 지정했다. Pascal Visual Object Challenge의 일환으로 2010 년부터 ImageNet 대규모 시각 인식 도전 (ILSVRC)이라는 연례 대회가 열렸다. ILSVRC는 1000 개의 카테고리 각각에 약 1000 개의 이미지가있는 ImageNet의 하위 집합을 사용한다. 전체적으로 약 120 만 개의 훈련 이미지, 50,000 개의 검증 이미지, 150,000 개의 테스트 이미지가 있다.
ILSVRC-2010은 테스트 세트 레이블을 사용할 수있는 유일한 ILSVRC 버전이므로 대부분의 실험을 수행한 버전이다. ILSVRC-2012 대회에도 이 모델을 도입했으므로 섹션 6에서는 테스트 세트 레이블을 사용할 수 없는 버전의 데이터 세트에 대한 결과도 보여준다. ImageNet에서는 두 가지 오류율을보고하는 것이 일반적이다. top-1 및 top-5, 여기서 top-5 오류율은 모델에서 가장 가능성이 높은 것으로 간주되는 5개 레이블 중 틀린 테스트 이미지의 비율이다. 
ImageNet은 가변 해상도 이미지로 구성되어 있지만 시스템에는 일정한 입력 차원이 필요하다. 따라서 이미지를 256 × 256의 고정 해상도로 다운 샘플링했다. 직사각형 이미지가 주어지면 먼저 짧은면의 길이가 256이되도록 이미지 크기를 조정 한 다음 결과 이미지에서 중앙 256x256 패치를 잘라낸다. 우리는 각 픽셀에서 훈련 세트에 대한 평균 활동을 빼는 것을 제외하고는 다른 방법으로 이미지를 사전 처리하지 않았다. 그래서 우리는 픽셀의 (중앙에 있는) 원시 RGB 값으로 네트워크를 훈련 시켰다.

3. 아키텍처
우리 네트워크의 아키텍처를 fig2에 요약했다. 여덟개의 학습 레이어(5개의 convolutional layer와 3개의 fc layer)를 포함한다. 아래에, 참신하고 비범한 우리 네트워크 아키텍쳐의 특징을 모사했다. 섹션 3.1-3.4는 가장 주요인 그들의 importance에 대한 우리의 추정에 따라 나열된다?

3.1 ReLU nonlinearity
뉴런의 출력값 f는 tanh(x)나 시그모이드로 설계하는 것이 일반적이다. 그라디언트로 학습하는 시간동안 이러한 포화 nonlinearities는 훨씬 느려진다 비포화 nonlinearity, max(0,x)보다. Nair와 Hinton에 따르면 우리는 비포화 뉴런을 Rectified Linear Units(ReLUs)라고 말한다. 딥 컨볼루셔널 뉴럴 네트워크는 동일 조건에서 tanh 유닛으로 학습시킬 때보다 ReLU로 학습 시킬 때 몇시간 빠르게 한다. Fig1에서 설명된다. 특정 네개 층 컨볼루셔널 네트워크에 대해 CIFAR-10 데이터셋으로 학습 시킬 때 25%의 학습 에러에 도달할때까지 요구되는 반복회수를 보여주고 있다. 이 도표는 우리가 만약 전통적인 포화 뉴런 모델을 사용했다면 이 작업에 대해서 이렇게 큰 뉴럴넷을 실험하는 것을 가능하게 하지 않았을 거라고 보여준다.

우리는 CNN에서 전통적인 뉴런 모델을 교체하기를 고려한 첫번째는 아니다. 예를 들어 Jarrett. 비선형함수 tanh는 Caltech-101 데이터셋에 대한 로컬 평균 풀링이 뒤따르는 대비 정규화 유형에서 특히 잘 작동한다고 주장한다.
그러나 이 데이터셋에서 주요 문제는 오버피팅을 막는 것이기 때문에 그들이 관찰하고 있는 효과가 ReLU를 사용할 때 우리가 보고한 트레이닝 셋에 적합하는 가속화된 능력과는 다를 겁니다. 빠른 학습은 규모가 큰 데이터셋으로 학습된 큰 규모의 모델의 성능에 좋은 영향을 준다.

3.2 멀티 GPU에서 학습
하나의 GTX580 GPU는 메모리가 3GB밖에 안된다 그리고 이것은 네트워크가 학습 될수 있는 최대 규모를 한정시킨다. 하나의 GPU에서 적합시키기에 너무 큰 1.2 million 학습 예제는 네트워크를 학습하기에는 충분하다는 것은 자명하다. 따라서 우리는 두개의 GPU에 네트워크를 분산시켰다. 현재 GPU는 그들이 호스트 머신의 메모리를 거치지 않고 서로 메모리로부터 읽어들이고 서로 메모리에 쓸 수 있기 때문에 특별히 크로스 GPU 병렬처리에 적합하다. 우리가 사용한 병렬 스키마는 하나의 부가적인 트릭에 의해 커널 또는 뉴런의 반을 각 FPU에 둔다.: GPU가 특정 레이어에서만 통신한다. 이것은 예를들자면 레이어3에서의 커널이 레이어 2에서 모든 커널 맵으로부터 입력받는다는 것을 의미한다. 그러나 레이어 4의 커널은 동일한 GPU에 있는 계층 3의 커널맵에서만 입력을 받는다.

연결 패턴을 선택하는 것은 cross validation에 대한 문제이지만 이런 점이 계산량의 허용 가능한 부분이 될 때까지 통신량을 정확하게 조정할 수 있다.

결과 아키텍처는 우리의 칼럼이 독립적이지 않다는 점을 제외하고서는 Ciresan에 의해 사용된 "columnar" CNN과 다소 비슷하다. 이 스키마는 하나의 GPU에서 학습된 각 컨볼루션 계층에 커널이 절반으로 많은 네트워크와 비교하여 top-1과 top-5 error rate을 각각 1.7%와 1.2%로 줄인다. 두개의 GPU를 사용하는 네트워크는 경미하게 학습 속도를 줄인다.

3.3 Local Response Normalization
ReLU는 포화로부터의 문제들을 막기위해 입력 정규화가 필요하지 않은 좋은 속성을 가진다. 적어도 일부 훈련 예제가 ReLU에 긍정적인 입력을 생성하면 해당 뉴런에서 학습이 발생한다. 적어도 일부 훈련 예제가 ReLU에 긍정적인 입력을 생성하면 해당 뉴런에서 학습이 일어난다. 그러나 우리는 여전히 따라오는 지역적 정규화 구조가 일반화에 도움이 된다는 것을 발견했다. x,y 위치에 i번째 커널을 적용함으로써 계산되는 뉴런의 activity인 aix,y를 표시하고 ReLU nonlinearity를 적용함으로써, 반응 정규화 activity인 bix,y가 다음의 표현식으로 주어진다.
(수식)
합은 동일한 공간 위치에 있는 n개의 "인접한" 커널 맵에서 실행되며, N은 계층의 총 커널 수를 말한다.  커널 맵의 순서는 임의적이며 훈련이 시작되기 전에 결정된다. 이러한 종류의 반응 정규화는 실제 뉴런에서 발견되는 유형에서 영감을 얻은 측면 억제의 한 형태를 구현하여 다른 커널을 사용하여 계산된 뉴런 출력 사이에서 activities에 대한 경쟁을 만든다. 상수 k,n, α, and β는 validation set을 사용하여 값이 결정되는 하이퍼파라미터이다; 우리는 k=2, n=5, α=10^{-4}, β = 0.75로 사용한다. 우리는 특정 레이어에 ReLU를 적용한 이후 이 정규화를 적용했다.
이 구조는 Jarrett의 local contrast normalization 구조와 일부 유사하다. 그러나 우리것은 평균 activity를 빼지 않으므로 더 정확하게 "밝기 정규화"라고 불릴 것이다. 반응 정규화는 우리의 top-1과 top-5 error rate를 각각 1.4%와 1.2%까지 줄인다. 우리는 또한 CIFAR-10 데이터셋에서 이 구조의 효과를 확실하게 한다.: 4개의 레이어 CNN은 정규화 없이 13% test error rate를, 정규화해서는 11% error rate을 달성했다.

3.4 Overlapping Pooling
CNN의 풀링 레이어는 같은 커널 맵 내 뉴런의 이웃 그룹의 출력을 요약한다. 전통적으로, 이웃은 인접 풀링 유닛에 의해 요약된 overlap하지 않는다.  더 정확하게는 풀링 레이어는 각 풀링 유닛의 위치를 중심으로 하는 zXz 크기의 이웃을 요약해서 s 픽셀 간격의 풀링 유닛 공간의 그리드로 구성된다고 생각될 수 있다. 만약 우리가 s=z로 세팅하면, 우리는 CNN에서 일반적으로 사용되는 전통적인 local 풀링을 포함하는 것이다. 우리가 만약 s<z로 설정하면 우리는 overlapping pooling을 포함하는 것이다. 이것이 우리 네트워크를 거쳐 s=2, z=3으로  사용한 이유다. 이 구조는 동등한 차원의 출력을 생산하는 s=2,z=2 non-overlapping 구조와 비교해서 top-1과 top-5 error rates를 0.4%와 0.3%까지 감소시켰다. 우리는 오버래핑 풀링을 이용하는 것이 학습 시간 동안 모델이 오버핏되는 것을 경미하게 좀더 어렵게 만든다는 것을 관측한다 

3.5 Overall 아키텍처
이제 우리는 우리의 CNN의 전체적인 아키텍처를 묘사할 준비가 되었다. Fig2에 따르면, 네트워크는 가중치와 함께 8개의 레이어를 포함한다; 첫번째 5개는 convolutional layer고 나머지 3개는 전연결되어있다. 마지막 전연결 층의 출력은 1000개 클래스 레이블에 대한 분포를 생산하는 1000 way softmax로 연결된다. 우리의 네트워크는 multinomial logistic regression objective를 최대화하며 예측 분포에서 정답 레이블의 log-probability에 대한 학습 케이스의 평균을 최대화하는 것과 동일하다.

두번째, 네번째, 다섯번째 컨볼루셔널 레이어의 커널은 같은 GPU로부터 나온 앞선 레이어에서 오직 이들의 커널맵하고만 연결되어있다. 세번째 컨볼루션 레이어는 두번째 레이어의 모든 커널맵과 연결되어있다. 전연결 층의 뉴런은 앞전 레이어에서 모든 뉴런과 연결되어있다. 반응 정규화 레이어는 첫번째와 두번째 레이어를 따른다. 섹션 3.4에서 묘사된 Max-pooling layer는 다섯번째 컨볼루션 레이어랑 반응 정규화 레이어 둘다에 적용된다. ReLU non-linearity는 모든 convolutional layer와 fully-connected layer에 대한 출력에 적용된다.
첫번째 convolutional layer는 4 pixel stride(커널맵 내 인접 뉴런 수용 필드 중심 사이의 거리)간격으로 11X11X3 사이즈의 커널 96개와 함께  224X224X3 입력이미지를 필터링한다. 두번째 컨볼루셔널 레이어는 입력으로 (반응-정규화되고 풀링된) 첫번째 컨볼루셔널 레이어의 출력을 갖으며, 5X5X48 사이즈의 커널 256개와 함께 필터링 된다. 세번째와 네번째, 다섯번째 convolutional layer는 어떠한 풀링이나 정규화 층의 개입 없이 서로서로 연결된다. 세번째 컨볼루셔널 레이어는 384개의 3X3X256 사이즈의 두번째 컨볼루셔널 레이어의 출력과 연결된 (정규화되고 풀링된)커널을 가진다. 네번째 컨볼루셔널 레이어는 3X3X192 사이즈의 384개의 커널을 가지며, 다섯번째 컨볼루셔널 레이어는 3X3X192 사이즈의 256개의 커널을 갖는다. 전연결 층은 각각 4096 뉴런을 갖는다.

