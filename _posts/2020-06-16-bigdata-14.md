---
title: "Building Spark Applications-Understading BigData(14)"
categories: 
  - BigData
last_modified_at: 2020-06-17T22:05:00+09:00
toc: true
published: false
---

Intro
---
학교 수강과목에서 학습한 내용을 복습하는 용도의 포스트입니다.<br/>
빅데이터 개념과 오픈소스인 아파치 하둡과 맵리듀스 및 스파크를 이용한 빅데이터 적용을 공부합니다.<br/>
맵 리듀스의 경우 사용하기에 다소 진입장벽이 있는편입니다.<br/> 스파크처럼 통합 환경을 제공하지 않아 원하는 유틸리티나 라이브러리를 별도로 연결해서 사용해야하기 때문입니다. 이를 해소하는 것이 스파크라는 분산 데이터 처리 통합 엔진입니다.<br/>
따라서 맵 리듀스로 먼저 공부해보고, 스파크로 넘어갑니다.<br/>

스파크 엔진의 경우 Java가 아닌 Scalar라는 언어로 사용하며, 기존 우리가 알고 있는 SQL을 통해 고급 질의가 가능하며, 시각화나 스트림 처리 및 기계학습등 까지의 높은 수준의 분석을 제공하는 통합 프레임 워크입니다.<br/>

빅데이터 컴퓨팅(분산시스템상의 분산처리 환경)의 기본 개념과 원리를 이해하고 이를 실습해보는 과정에서 2대 이상의 리눅스 클러스터 서버를 구축 및 활용할 것입니다.<br/>

[빅데이터이해(1) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-1/)<br/>
[빅데이터이해(2) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-2/)<br/>
[빅데이터이해(3) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-3/)<br/>
[빅데이터이해(4) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-4/)<br/>
[빅데이터이해(5) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-5/)<br/>
[빅데이터이해(6) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-6/)<br/>
[빅데이터이해(7) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-7/)<br/>
[빅데이터이해(8) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-8/)<br/>
[빅데이터이해(9) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-9/)<br/>
[빅데이터이해(10) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-10/)<br/>
[빅데이터이해(11) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-11/)<br/>
[빅데이터이해(12) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-12/)<br/>

이번 시간에는 지난 시간에 이어서 스파크 응용 구축에 대해 배웁니다.<br/>
스파크 프로그램 수명주기, 스파크 응용 실행 환경, SFPD 스파크 응용 순서대로 학습하겠습니다.<br/>

Life Cycle of Spark Program
---
여태까지 우리가 배웠떤 스파크 프로그램이 실행되는 단계는 아래와 같습니다.<br/>

스파크응용을 관리하고 정보를 유지하면서 작업들을 각 분산 노드에 배포하는 역할의 응용을 Driver Program이라고 합니다.<br/>
이러한 Driver Program 상에 베이스 데이터세트를 생성해줍니다.<br/>

우리가 원하는 활용도에 맞게 데이터를 변환하고 액션하게 됩니다.<br/> 이 때 우리는 베이스 데이터세트를 변경하는 것이 아니라 immutable하기 때문에 새로운 데이터세트를 정의하는 것입니다.<br/>
지연 변환이 적용될 것이구요.<br/>

그 과정에서 재사용될 데이터세트의 경우 캐싱을 해줍니다.<br/>

실제 액션을 수행하게 되면 지연된 변환 과정이 수행되고 결과를 산출합니다.<br/>

스파크의 구성요소로는 스파크 세션이 있는 Driver Program이 있고, 물리적인 자원을 관리 및 할당하는 클러스터 관리자, Worker node가 있습니다.<br/>

그래서 크게 실행자 프로세스를 실행하는 worker node, Driver Program 두 가지로 구성된다고 말할 수 있습니다.<br/>

스파크는 마스터\-슬레이브 구조로 구성되어있습니다.<br/>
그리고 하나의 중앙 중재자 역할의 드라이버가 있고, 많은 분산 작업자들이 있습니다.<br/>

드라이버와 작업자들은 각각 자신의 자바프로세스를 실행합니다.<br/>

이러한 드라이버와 실행자를 묶어서 우리는 스파크 응용이라고 부릅니다.<br/>

스파크에 대한 응용을 실행하기 위해서는 응용을 드라이버프로그램에 submit 해주어야합니다.<br/>

사용자는 spark\-submit 명령으로 스파크 응용을 제출합니다.<br/>

이 명령어로 드라이버 프로그램이 시작되며 main() 메소드를 호출하게되고 main() 메소드에서는 SparkSession을 생성하게 됩니다.<br/>

SparkSession은 클러스터 관리자의 위치를 드라이버에게 알려줍니다.<br/>

그래서 독자적인 응용으로 빌드하고 구축할 때는 main()을 작성해주어야 합니다.<br/>

드라이버 프로그램은 자원을 요청하고 실행자의 실행을 위해 드라이버 클러스터 관리자에 연결합니다.<br/>

이후 클러스터 관리자는 드라이버 프로그램을 위한 실행자를 실행합니다.<br/>

정리하자면 드라이버는 응용을 실행하는데, SparkSession을 생성하고 데이터세트를 정의하고, 변환을 수행하며 액션을 적용하게 됩니다.<br/>

이러한 내용이 기술된 Jar 또는 python 파일의 작업을 태스크 형식으로 실행자에게 전송하게 됩니다.<br/>

실행자의 태스크들을 실행할 때에는 태스크 단위로 분산되어 병렬 실행하게 됩니다.<br/>

응용의 종료 시에는 Main() 메소드가 SparkSession.stop을 호출하여 응용을 종료하게 됩니다.<br/>

한 번 더 정리하면 아래와 같습니다.<br/>
1. 사용자는 응용을 작성한 후 spark\-submit 명령을 입력
2. Driver Program 실행하여 데이터세트 생성, 변환, 액션을 수행 빌드 내용을 물리적 자원 관리하는 Cluster Manager에게 연결
3. Cluster Manager는 자원을 분산 할당
4. 실행자가 실행됨
<br/>

스파크 응용 실행 환경
---
스파크는 클러스터 관리자를 통해 실행자를 실행시킨다고 했습니다.<br/>
클러스터 관리자는 스파크의 플러그가 가능한 컴포넌트들이어서 Hadoop YARN, Apache

15:19
