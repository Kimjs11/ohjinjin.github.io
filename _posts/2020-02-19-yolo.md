---
title: "Analyze YOLO neural network for object detection"
categories: 
  - MachineLearning
last_modified_at: 2020-02-23T12:57:00+09:00
toc: true
---

object detection을 제공하는 강력한 라이브러리인 YOLO를 간단하게 분석하여 그 내용을 기록하려고 합니다.<br/>
<br/>


Object Detection
-------
컴퓨터 비전 접목 딥러닝 객체 검출과 관련하여 여러 기술 및 용어가 있습니다.<br/>

그 중 classification과 object detection, segmentation 분야를 구분해봄으로써 Object detection에 대한 대략적인 이해를 먼저 해보려고 합니다.<br/>
{% raw %} <img src="https://ohjinjin.github.io/assets/images/20200219yolo/capture1.jpg" alt=""> {% endraw %}

1. **Classification**<br/>
첫 번째 분류(Classification)란 입력 이미지 별 Class label을 구분하는 기술입니다.<br/>
분류는 이후 세 가지 기술의 근간이 되는 기술이므로 우선적인 이해가 필요합니다. 그래서 대표적인 모델인 CNN에 대한 설명을 작성해 놓은 링크를 [여기](https://ohjinjin.github.io/machinelearning/CNN/)에 걸어드리겠습니다.<br/>
보통 우리가 다루게 될 이미지들은 그 이미지 내 다양한 객체들이 다양한 영역에 분포가 되어있고 이를 인식 및 추출하기 전에 어디 영역에 있는지를 확인해 줄 필요가 있습니다.<br/>

2. **Localization**<br/>
그림상 두 번째 Localization은 이미지 안에 ROI 즉 우리가 찾고자 하는 Object가 전체 영상 내 어디에 존재하는 지 위치 정보를 출력해주는 기술입니다.<br/>
주로 bounding box가 이에 사용됩니다.<br/><br/>

3. **Detection**<br/>
세 번째 객체 탐지(Object Detection)란 classification과 Localization이 동시에 수행되는 기술입니다.<br/>
모델의 학습 목적에 따라 특정 객체만 탐지하는 경우도 있고 멀티 클래스의 객체를 탐지하는 경우도 있으며, 때로 위치정보만을 파싱해오는 데에만 사용되어 Localization의 의미로만 사용되는 경우도 있습니다.<br/>
Object detection 기술에서의 Localization 구현에 있어서도 역시 bounding box가 흔히 사용됩니다.<br/>

4. **Segmentation**<br/>
네 번째 object segmentation은 object detection을 통해 검출된 객체의 형상을 따라서 해당 객체의 영역을 표시하는 기술을 말합니다.<br/>
보통 이미지의 각 pixel을 classification하여 경계를 따낸 결과를 도출한다고 합니다.<br/>
이 기술은 배경과 전경을 구분하는 용도로도 흔히 사용됩니다.<br/>

조금 더 자세히 설명하자면 이미지 전체에 대한 영역을 분할하는 기술은 Image segmentation이라고 불리는데 이렇게 분할된 영역들에 대해 각 의미요소를 찾는 적당한 알고리즘을 접목시켜 object segmentation을 수행합니다.<br/>

이 중 제가 분석하고자 하는 YOLO 네트워크는 바로 세 번째 **객체 탐지**를 구현한 라이브러리입니다.<br/><br/>

Systems for object detection
------
object detection을 제공하는 시스템은 제가 사용한 **YOLO(You Only Look Once)** 말고도 **R-CNN계열**과 **SSD(Single Shot Multibox Detector)** 등이 있습니다.<br/>
이들의 장단점을 간단히 비교해 놓은 글 링크를 [여기](https://jetsonaicar.tistory.com/12)에 걸어두겠습니다.<br/><br/>

YOLO(You Only Look Once)
------
YOLO는 C/C++호환 버전의 **darknet**으로도 구현되었고, python tensorflow 버전인 **darkflow**로도 구현되어 제공되고 있습니다.<br/>
* [darknet 튜토리얼 보러가기](https://ohjinjin.github.io/machinelearning/darknet-1/)
* [darkflow 튜토리얼 보러가기](https://ohjinjin.github.io/machinelearning/darkflow-1/)

<br/>
YOLO 네트워크의 Object Detection 시행에 대한 워크 플로우는 아래와 같습니다.<br/>

{% raw %} <img src="https://ohjinjin.github.io/assets/images/20200219yolo/capture2.JPG" alt=""> {% endraw %}

1. **이미지 분할 단계**<br/>
S x S grid로 전체 이미지를 분할합니다.<br/>

2. **경계박스에 대한 proposal 단계**<br/>
분할된 이미지에서 특정 객체의 중심 커널이 포함될 경우 그 부분을 탐지해볼 필요가 있다는 컨셉으로 proposal이 이루어집니다.<br/>

3. **경계박스별 score 계산 및 threshold와의 대소비교를 통한 출력**<br/>
Score 계산식은 아래와 같습니다.<br/>

{% raw %} <img src="https://ohjinjin.github.io/assets/images/20200219yolo/capture3.jpg" alt=""> {% endraw %}

(이미지 분할, 경계박스생성, 스코어계산후 thrsh와의 대소비교 등 워크플로우 크게 먼저 설명)<br/>
(스코어 계산식 쪽 자세히 설명)<br/>
(최적화와 로스함수까지)<br/>
<br/>
<br/>
(수정중)<br/>